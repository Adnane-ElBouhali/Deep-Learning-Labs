# Introduction to Deep Learning - Practical Works

This repository contains practical lab works completed as part of the SD-TSIA203 course: Introduction to Deep Learning at Télécom Paris.

## Course Description

This course provides a theoretical understanding and practical application of the three main types of neural networks (Multi-Layer Perceptron, Recurrent Neural Networks, and Convolutional Neural Networks) and the main generation paradigms (GAN and VAE). The content ranges from the perceptron to the generation of adversarial images.

## Instructors

- Geoffroy Peeters
- Stéphane Lathuilière (Telecom Paris, IP-Paris)

## Learning Objectives

By the end of this course, students will be able to:

- Understand the theory underlying the main deep learning architectures
- Comprehend different generation paradigms: GAN, VAE
- Program these architectures in Python using popular deep learning frameworks (PyTorch and Keras)
- Apply these to typical computer vision, NLP, or audio problems such as classification, regression, or generation

## Lab Works

1. **Lab 1: Multi-Layer Perceptron**
   - Notebook for function approximation (regression) using Deep Learning
   - Notebook for Image (MNIST) classification using Deep Learning

2. **Lab 2: Convolutional Neural Networks (CNNs)**
   - Implementation of CNNs in PyTorch

3. **Lab 3: Recurrent Neural Networks (RNNs)**
   - Notebook for IMDB review classification using RNN
   - Notebook for Bach generation using LSTM, language model, and sampling

## Course Outline

1. **Lecture 1**: From regression and kernel regression to multi-layer perceptron, including optimization (SDG, Newton, Momentum, AdaGrad), logistic/softmax regression, classification, backpropagation, chain rule, regularization (L1, L2), and loss definitions.

2. **Lecture 2**: Convolutional Neural Networks: backpropagation, pooling, well-known networks, transfer learning.

3. **Lecture 3**: Deep Generative Models: Image generation with GANs (Deconvolution, DCGAN, Inception Score, Wasserstein GAN, Image-to-Image Translation, CycleGAN), Video generation with GANs (MoCoGAN), Auto-Encoders, VAE.

4. **Lecture 4**: From Recurrent Neural Networks to Transformers, including backpropagation through time, LSTM, applications to NLP.

## Keywords

Machine learning, deep learning, artificial intelligence, logistic regression, multi-layer perceptron, recurrent neural network, transformer, convolutional neural network, GAN, VAE

## Note

This repository contains only the practical works completed during the course. For full course materials or additional information, please refer to the official course documentation at Télécom Paris.